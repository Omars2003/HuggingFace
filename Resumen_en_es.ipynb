{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omars2003/HuggingFace/blob/main/Resumen_en_es.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBfZOGBQ__84"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPa8DcBYAG-Q"
      },
      "outputs": [],
      "source": [
        "!pip install datasets #para este modelo ocuparemos Amazon_reviews we only will use english and spanish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E0nXOdiMA32p"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2NkiPdTBC1g"
      },
      "outputs": [],
      "source": [
        "spanish_dataset = load_dataset(\"amazon_reviews_multi\", \"es\")\n",
        "english_dataset = load_dataset(\"amazon_reviews_multi\", \"en\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2di6np4CZ2S",
        "outputId": "3bc11997-b468-45ff-e36d-be4611c467ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 200000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are interested in is contained in the review_body and review_title columns"
      ],
      "metadata": {
        "id": "g7cGSuT2FAlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def muestra_ejemplos(dataset, num_samples=4, seed=50):#seed=un grupo de 50\n",
        "    ejemplos = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples)) #shuffle funtion cambia el orden \n",
        "    for example in ejemplos:\n",
        "        print(f\"\\n'>> Title: {example['review_title']}'\")\n",
        "        print(f\"'>> Review: {example['review_body']}'\")\n",
        "\n",
        "\n",
        "muestra_ejemplos(english_dataset)\n",
        "muestra_ejemplos(spanish_dataset)"
      ],
      "metadata": {
        "id": "R7CbOENZGN5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Training a summarization model on all 400,000 reviews would take far too long on a single GPU, so instead we’ll focus on generating summaries for a single domain of products."
      ],
      "metadata": {
        "id": "v_ugCtPXIBC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a feel for what domains we can choose from, let’s convert english_dataset to a pandas.DataFrame and compute the number of reviews per product category:"
      ],
      "metadata": {
        "id": "_48qEfArIHKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset.set_format(\"arrow\") #arrow or #pandas\n",
        "english_df = english_dataset[\"train\"][:]\n",
        "# Show counts for top 20 products\n",
        "english_df[\"product_category\"].value_counts()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5562VirVIHv9",
        "outputId": "44eb261e-d3a1-4cde-b10e-d63707e89fbc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.StructArray object at 0x7f81dbf39910>\n",
              "-- is_valid: all not null\n",
              "-- child 0 type: string\n",
              "  [\n",
              "    \"furniture\",\n",
              "    \"home_improvement\",\n",
              "    \"home\",\n",
              "    \"wireless\",\n",
              "    \"pc\",\n",
              "    \"industrial_supplies\",\n",
              "    \"kitchen\",\n",
              "    \"apparel\",\n",
              "    \"automotive\",\n",
              "    \"camera\",\n",
              "    \"lawn_and_garden\",\n",
              "    \"watch\",\n",
              "    \"beauty\",\n",
              "    \"pet_products\",\n",
              "    \"drugstore\",\n",
              "    \"electronics\",\n",
              "    \"toy\",\n",
              "    \"digital_ebook_purchase\",\n",
              "    \"book\",\n",
              "    \"jewelry\"\n",
              "  ]\n",
              "-- child 1 type: int64\n",
              "  [\n",
              "    2984,\n",
              "    7136,\n",
              "    17679,\n",
              "    15717,\n",
              "    6401,\n",
              "    1994,\n",
              "    10382,\n",
              "    15951,\n",
              "    7506,\n",
              "    2139,\n",
              "    7327,\n",
              "    761,\n",
              "    12091,\n",
              "    7082,\n",
              "    11730,\n",
              "    6186,\n",
              "    8745,\n",
              "    6749,\n",
              "    3756,\n",
              "    2747\n",
              "  ]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I8o_mxnqKAi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are going to use the books and e-books reviews, so we need to separate their reviews.\n",
        "\n",
        "Now when we apply this function to english_dataset and spanish_dataset, the result will contain just those rows involving the book categories. Before applying the filter, let’s switch the format of english_dataset from \"pandas\" back to \"arrow\":"
      ],
      "metadata": {
        "id": "_qBjxpOqKBIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filtros_books(example):\n",
        "    return (\n",
        "        example[\"product_category\"] == \"book\"\n",
        "        or example[\"product_category\"] == \"digital_ebook_purchase\"\n",
        "    )"
      ],
      "metadata": {
        "id": "a307Y0loKIoH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset.reset_format()\n",
        "spanish_dataset.reset_format()"
      ],
      "metadata": {
        "id": "Wlp-nGbSLrkP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_books = spanish_dataset.filter(filtros_books)\n",
        "english_books = english_dataset.filter(filtros_books)\n",
        "muestra_ejemplos(english_books)\n",
        "muestra_ejemplos(spanish_books)"
      ],
      "metadata": {
        "id": "u44I_agFKmnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WE HAVE a last step about data and itscombining the English and Spanish reviews as a single DatasetDict objec"
      ],
      "metadata": {
        "id": "d-4jm5pTMl8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "oncatenate_datasets() function that (as the name suggests) will stack two Dataset objects on top of each other. So, to create our bilingual dataset, we’ll loop over each split, concatenate the datasets for that split, and shuffle the result to ensure our model doesn’t overfit to a single language:"
      ],
      "metadata": {
        "id": "-mqSXcqtNHwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_Pnn1OzdNIdq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Resumen_en-es.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGgj3x9liXT3cY1H9HZlhQ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}